<오전>
컴퓨터 비전 - 이미지 및 비디오 : 인지 인공지능의 하위 분야, 기계에게 이미지와 비디오를 이해하도록 가르치는 기술. 자율 주행, 스포츠 분석, 군중 감시, 그리고 비디오 게임 제작과 같은 다양한 분야에 적용된다.

(컴퓨터 비전 - 이미지)
* 이미지 분류(Image Classification) : 표현하고자 하는 사물에 따라 이미지를 분류할 수 있는 능력을 의미한다. ImageNet 벤치마킹에서 인간보다 뛰어난 능력을 보이는 등 상당한 수준에 도달했다.
* 얼굴 검출 및 인식(Face Detection and Recognition) : 이미지나 비디오에서 인공지능이 얼굴을 인식할 수 있는 능력을 의미.
* 딥페이크 검출(Deepfake Detection) : 인공지능 기술을 이용하여 인간 이미지를 합성하는 기술을 의미. (Deep Learning과 Fake의 합성어) 인간과 AI는 deepfake 검출에 다른 특징을 보이기는 하지만, 대체적으로 동등한 수준에 이름.
* 인간 자세 추정(Human Pose Estimation) : 이미지에서 인간 신체가 어떤 자세를 취하고 있는지를 예측하는 작업을 의미한다.
* 의미 분할(Semantic Segmentation) : 개별적인 이미지 픽셀(화소)을 특정한 범주로 나누는 것을 말한다. 자율주행이나 의학 영상 진단 등에서 적극 활용됨. 2014년 이후 23.4%p라는 상당한 개선이 있었지만 최근에는 정체되는 경향이 있다.
* 의료 이미지 분할(Medical Image Segmentation) : AI 모델은 이미지 내 병변이나 장기 등의 개체를 분할 할 수 있다.
* 개체 감지(Object Detection) : 이미지나 비디오내에서 개체를 식별하고 위치를 알아내는 것을 개체 감지라고 한다.
* 이미지 생성 (Image Generation) : 실제 이미지와 구별할 수 없는 이미지를 만들어내는 작업을 의미한다. 현재는 사람들이 쉽게 구분하기 어려울 정도로 발전했다.
* 시각적 추론 (Visual Reasoning) : AI 시스템이 텍스트와 시각적 데이터를 모두 고려하여 추론할 수 있는 능력을 의미한다.
최근 연구가 시작된 VCR은 주어진 문제에 답을 하는 동시에 그 답을 선택한 ‘이유‘를 제시해야 한다.
* 활동 인식 (Activity Recognition) : 비디오에서 발생하는 활동들을 분류하는 것을 의미한다.

(언어 및 음성)
자연어 처리(NLP)는 컴퓨터 시스템이 텍스트를 이해하는 능력을 의미한다. 최근 많은 대형 언어 모델들(PaLM, GPT-3, GLM-130B 등)이 출시되었으며, 방대한 양의 데이터로 훈련되어 다양한 하위 작업에 적응할 수 있는 능력을 포함하게 됨.
* 영어 언어 이해 (English Language Understanding) : 영어 독해 능력을 보는 분야로, 상식 및 논리적 추론을 통한 ‘Yes/No’ 또는 ‘객관식‘ 답변으로 테스트함.
* 텍스트 요약 (Text Summarization) : 텍스트를 요약하는 능력.
* 자연어 추론 (Natural Language Inference) : 주어진 가설이 참(True), 거짓(False) 또는 결정되지 않았는지(underdetermined) 판단하는 능력을 의미.
* 감성 분석 (Sentiment Analysis) : 텍스트에 나타난 감정의 식별을 위해 자연어 처리 기술을 적용하며, 주로 비즈니스 분야에서 고객 리뷰를 파악하기 위해 사용된다.
* 다중 작업 언어 이해 (Multitask Language Understanding) :  언어 모델이 여러 전문 분야 영역을 넘나드는 이해 및 추론 능력을 의미한다.
* 기존 벤치마크(GLUE, SuperGLUE 등)는 모델이 학습한 지식을 다양한 영역에 적용하는 능력 테스트에 한계.
* 기계 번역 (Machine Translation) : DeepL이나 Google 번역과 같은 신경망 기반 기술이 주도.
기계 번역 서비스는 가장 인기있는 AI 언어 서비스 중 하나이며, 상용 서비스 수는 지속적으로 증가하고 있다.
* 음성 인식 (Speech Recognition) : AI 모델이 음성 단어를 식별하고, 텍스트로 변환하고, 화자를 구분하는 것을 의미.
컴퓨터 프로그램, 문자 메시지 앱 등에서 음성을 문자로 자연스럽게 변환할 수 있는 수준까지 발전함.

* 개요 : GPT-4, Gemini 등 많은 첨단 LLM들은 유창하고 일관된 글을 생성하고 높은 언어 이해 능력을 보입니다.
또한, 이 모델들은 이미지와 오디오 등 여러 입력 형태를 동시에 처리합니다
* 이해 (Understanding) : 인공지능이 SQuAD (질의응답) 및 SuperGLUE(언어이해) 벤치마크에서 인간의 능력을 넘어서면서 HELM(Holistic Evaluation of Language Models)과 같이 독해, 언어 이해, 수학적 추론 등 다양한 시나리오를 포함하여 전체적인 평가를 할 수 있는 벤치마크들이 개발되었습니다.
* HELM -  mean win rate : HELM에서 사용하는 지표 중에서 평균 승률(mean win rate)을 보여주는 그래프로서, GPT-4가 선두를 달리고 있다.
* 다중 작업 언어 이해 : 언어 모델이 특정한 전문 분야 영역을 넘나드는 추론 능력을 테스트합니다.
다중 작업 언어 이해는 언어 모델이 여러 전문 분야 영역을 넘나드는 이해 및 추론 능력을 의미.
기존 벤치마크(GLUE, SuperGLUE 등)는 모델이 학습한 지식을 다양한 영역에 적용하는 능력 테스트에 한계.
* 생성 : 인공지능 모델은 유창하고 실질적인 언어 답변을 제공하는 능력을 측정.
* 사실성과 정직함 : 비록 주목할 만한 성취가 있음에도, LLM들은 사실적인 부정확성과 콘텐츠 환각에 취약합니다. 이로 인해 겉으로는 현실적으로 보이지만 사실이 아닌 정보가 생성됩니다. 현실 세계에서 LLM이 환각을 일으킨 사례들이 종종 보고 되고 있으며, 따라서 LLM 사실성의 추세를 밀접히 모니터링하는 필요성이 점점 더 강조됩니다.

(코딩)
* 생성 : 인공지능 모델들은 이제 코드를 생성하거나 컴퓨터 과학 문제를 푸는 것도 도전중이다.
인공지능 시스템의 코딩 성능이 향상되면서 더욱 도전적인 과제들이 벤치마크로 제시되고 있습니다.

(컴퓨터 비전 및 이미지 생성)
컴퓨터 비전은 기계가 이미지와 비디오를 이해하고 텍스트 프롬프트나 기타 입력으로부터 현실적인 시각 자료를 생성할 수 있게 합니다. 이 기술은 자율 주행, 의료 영상, 비디오 게임 개발 등의 분야에서 널리 사용되고 있습니다.
* 이미지 생성 기술의 발전 속도 : 인공지능 기술은 이미지 생성 분야에서도 매우 빠른 발전 속도를 보이고 있습니다.
* 생성 : 2023년 스탠포드 연구진이 공개한 HEIM(Holistic Evaluation of Text-to-Image Models)은 다양한 관점에서
이미지 생성 모델을 평가하고자 하는 시도입니다.
* 생성 - MVDream : 3차원 기하/모델을 만드는 작업은 3D 데이터를 기반으로 작업하거나 2D 생성 모델을 3D 생성에 활용하는 기법 등을 활용한다. 하지만 Multi-View에 대한 포괄적 지식이 부족함에 따라 Multi-face Janus Problem, Content Drift Problem 등의 문제가 있다.
* MVDream은 텍스트 입력으로부터 3차원 모델을 생성하는 Multi-view Diffusion 모델입니다. 일관성과 안정성을 높이기 위하여 2D 및 3D 데이터로 학습하여, 기존 모델의 문제점이었던 Janus Problem과 Content Drift Problem을 극복한 모델로 평가받고 있습니다.
* 지시 사항 따르기 : 인공지능 비서의 개발을 위해서 지시사항 따르기를 할 수 있는 비전 – 언어 모델이 개발되고 있으며, 이를 위한 벤치마크가 2023년에 소개되었습니다.
* 편집 : 프롬프트에 맞춰 이미지를 변형하는 기술을 통해 엔지니어링, 산업 디자인, 영화제작 등에서 활용하려는 시도가 진행되고 있습니다.
* 편집 - ControlNet : 인공지능이 이미지를 생성할 때, 텍스트 프롬프트를 기반으로 생성하는 경우 다양한 조건 (복잡한 레이아웃, 다양한 모양, 특정한 자세 등)을 만족시키기는 쉽지 않습니다. 2023년 스탠포드에서 만든 ControlNet을 사용하면 복잡한 포즈도 점과 선으로 이루어진 간단한 가이드로 이미지를 생성할 수 있게 합니다.
* 편집 - Instruct-NeRF2NeRF : NeRF로 생성된 3차원 형상에 텍스트 프롬프트를 추가해서 새로운 3차원 형상 (NeRF)를 만드는 기술 (NeRF to NeRF)로 기존의 3차원 형상을 변형하는데 효과적인 기술입니다.
[참고] NeRF : NeRF (Neural Radiance Fields)는 2D 이미지를 3D 이미지로 변환하는 기술로서 여러 방향에서 사진찍은 물체의 이미지를 입력으로, 새로운 시점에서의 이미지로 생성하는 기술입니다. 이 기술은 NVIDIA의 하드웨어 기술을 활용하여 Instant NeRF로도 활용되고 있습니다.
* 분할 - Segment Anything : Meta에서 2023년에 만든 Segment Anything은 이미지에서 개체들을 분리할 수 있는 도구입니다. 
기존의 segment 모델인 RITM과 비교한 결과 23개의 데이터셋 기준 16개에서 앞서는 성능을 보였습니다
* 3차원 이미지 생성 - Skoltech3D : 2차원 이미지에서 3차원 이미지를 만드는 3차원 이미지 재건 작업은 의학 이미지, 로보틱스, 가상 현실 등에서 사용 가능한 기법입니다. SKoltech3D는 이러한 작업을 위해서 만들어진 데이터셋입니다.
* 3차원 이미지 생성 - RealFusion : 3D 모델을 만드는 여러 시도 중에서 단일 2D 이미지를 통해서 3D 모델을 만드는 기법도 있습니다.

(비디오 컴퓨터 비전 및 비디오 생성)
비디오 분석은 단일 이미지가 아닌 비디오 전반에 걸쳐 작업을 수행하는 것을 의미합니다.
* 생성 : 비디오 생성과 관련하여 University of Central Florida(UCF)에서 만든 UCF 101 데이터셋 (101가지의 동작 카테고리를 갖는 13,320 개의 비디오 데이터 집합)을 기반으로 비디오 생성 벤치마크의 대상으로 활용하고 있습니다.
* 생성 - Align Your Latents : 대부분의 기존 방법들이 짧고 저해상도의 비디오만 생성할 수 있는 한계가 있어서, 이러한 한계를 해결하기 위해 Align Your Latents라는 연구가 제시되었습니다.
* 생성 - EmuVideo : 전통적으로 비디오 생성은 이미지 생성에 비해 복잡성이 높고 훈련을 위한 데이터셋이 적기 때문에 어려운 과제였습니다. Meta 연구진이 만든 새로운 트랜스포머 기반 비디오 생성 모델인 Emu Video는 텍스트로부터 이미지를 생성한 다음, 해당 텍스트와 이미지를 기반으로 비디오를 만드는 기법입니다.

(추론)
AI에서 추론은 다양한 형태의 정보로부터 논리적으로 유효한 결론을 도출하는 AI 시스템의 능력을 의미합니다. 점점 더 다양한 추론 맥락에서 AI 시스템에 대한 테스트가 진행되고 있으며, 여기에는 시각적 추론(이미지에 대한 추론), 도덕적 추론(도덕적 딜레마 이해), 사회적 추론(사회적 상황 탐색)이 포함됩니다.
* 일반 추론 : 지난 몇년간 인공지능의 추론 관련 능력이 향상되면서 전통적인 벤치마크 도구였던 SQuAD(텍스트 추론) 및 VQA(시각적 추론)의 벤치마크 로서의 기능이 약해지면서 새로운 도구의 도입이 요구되었습니다.
2024년 1월 기준으로 가장 우수한 모델은 Gemini Ultra로, 전체적으로 59.4%의 점수를 기록하여 여러 과목에서 선두를 달리고 있습니다. 대부분의 개별 과제 부문에서 최고 모델은 여전히 중간 수준의 인간 전문가를 넘어서지 못하고 있고, 역설적으로 이 낮은 점수가 MMMU(Massive Multi-discipline Multi-modal Understanding & Reasoning)의 벤치마크로서의 역할을 보여줍니다.
NYU, Anthropic 및 Meta의 연구진이 도입한 GPQA(A Graduate-Level Google-Proof Q&A Benchmark)는 448개의 다지선다형 문제로서 Google 검색으로 쉽게 해결하기 어려운 문제들을 모은 벤치마크입니다.
* 추상적 추론 : 현재 AI 연구자들은 인간 고유의 인지 과정을 인공지능이 어느정도까지 모방할 수 있는가에 초점을 맞추고 있습니다. 추상적 추론은 제한된 정보에서 패턴을 파악하고 일반적인 원리를 추론하는 것을 의미하며 인간의 인지 능력에서 매우 중요한 요소입니다.
* 수학적 추론 : 약 8,000여 가지 다양한 학년별 수학 문제(문장으로 구성된)의 데이터셋으로 구성한 GSM8K (Grade School Math 8K)는 산술 연산을 활용하여 다단계로 이뤄지는 문제 해결 능력을 평가하는데 활용되고 있습니다.
LLM을 통해 계획을 수립하는 시스템을 만들 수 있다는 연구 이후 Arizona 주립대학에서 고안한 PlanBench는 국제 플래닝 공모전(International Planning Competition) 등에서 사용하는 문제들로 구성되어 있고, 이를 통해 인공지능의 계획 수립 능력을 평가하고 있습니다.
* 시각적 추론 : VCR(Visual Commonsense Reasoning)은 주어진 이미지에 대해서 답을 하는 것과 함께 그 선택의 ‘이유‘를 제시해야 합니다. 참고로 VCR은 2023 리포트에도 있었던 벤치마크입니다.
* 도덕적 추론 : 인공지능에서 도덕적 고려가 점점 더 중요해지면서 (예: 의료, 법률), 확고한 도덕적 추론 능력이 요구되며, 이를 테스트할 수 있는 벤치마크가 등장하게 되었습니다.
* 인과 추론 : 인과 추론에서는 인공지능 시스템이 인과관계를 이해할 수 있는지를 보게 됩니다. 인공지능 연구자들은 LLM의 Theory-of-Mind(ToM) 역량(믿음, 의도, 감정 등과 같은 정신 상태를 이해하고 인지하는 역량)을 개선하기 위해 노력해왔습니다.

(오디오)
AI 시스템은 인간의 음성을 처리하는 데 능숙하며, 음성을 텍스트로 변환하고 개별 화자를 인식하는 기능을 포함합니다. 최근에는 AI가 합성 음성 콘텐츠를 생성하는 데에서도 발전을 이루었습니다.
* 생성 - UniAudio : UniAudio는 오디오 콘텐츠를 생성하기 위한 고급 언어 모델링 기법입니다.
* 생성 - MusicGEN and MusicLM : Meta의 MusicGen은 언어 모델에서 흔히 사용하는 트랜스포머 아키텍처를 활용하여 오디오를 생성하는 새로운 오디오 생성 모델입니다. MusicGen은 사용자가 원하는 오디오 결과를 위해 텍스트를 지정하고, 특정 멜로디를 사용하여 미세 조정할 수 있습니다.

(에이전트)
AI 에이전트는 특정 환경에서 목표를 달성하기 위해 설계된 자율적 또는 반자율적 시스템으로, 현재 최신 AI 연구 분야입니다. 이러한 에이전트는 학술 연구 지원, 회의 일정 조정, 온라인 쇼핑, 휴가 예약 등 다양한 잠재적 응용 분야를 가지고 있습니다.
* 일반 에이전트 - LLM 기반 에이전트가 등장하면서 (예: AutoGPT), 특정 환경에서 지시한 자율적으로 작업을 수행할 수 있는지 평가하는 벤치마크가 만들어 졌습니다.
* GPT-4, Claude 2 및 Llama 2 등을 기반으로 한 25개 이상의 LLM 기반 에이전트를 평가하였으며, GPT-4가 4.01로 가장 높은 점수를 받았으며, Claude 2의 2.49점보다 크게 높았습니다.
* Voyager - Voyageur는 마인크래프트를 위해 만든 GPT-4 기반 에이전트입니다. Voyager는 이 환경에서 계획을 기억하고, 새로운 설정에 적응하며, 지식을 전이하는 데 능숙합니다. 
* 작업 특화 에이전트 - 수학 문제 해결이나 학문적 연구 등의 환경에서 동작하는 에이전트에 대한 벤치마크도 나타나고 있습니다.

(로보틱스)
시간이 지나면서 AI는 로봇공학에 점점 더 통합되어 로봇의 복잡한 작업 수행 능력을 향상시키고 있습니다. 
특히 파운데이션 모델의 등장으로 인해 이러한 통합은 로봇이 주변 환경에서 반복적으로 학습하고, 새로운 환경에 유연하게 적응하며, 자율적으로 결정을 내릴 수 있게 합니다.
* PaLM-E - Google에서 개발한 새로운 AI 모델로서 로봇 공학과 언어 모델링을 결합하여 로봇 조작, 지식 작업, 질문 응답, 이미지 캡션 작성 등 실제 작업을 처리합니다. 트랜스포머 기반으로 다양한 시각 언어 및 로봇 공학 데이터를 학습하여 다양한 로봇 벤치마크에서 우수한 성능을 발휘합니다.
* RT-2 - Google DeepMind에서 만든 RT-2는 LLM 기능을 갖춘 일반화 가능한 로봇 모델을 만들기 위한 시도입니다. 
RT-2는 트랜스포머 기반 아키텍처를 사용하며, 텍스트로 토큰화된 로봇 궤적 데이터와 광범위한 시각-언어 데이터를 학습합니다.

(강화학습)
강화 학습에서 AI 시스템은 이전 행동으로부터 상호 작용적으로 학습하여 주어진 작업에서 성능을 극대화하도록 훈련됩니다. 시스템은 원하는 목표를 달성하면 보상을 받고, 실패하면 페널티를 받습니다.
* RLHF : RLHF(Reinforcement Learning from Human Feedback)는 기존 강화학습의 보상 함수에 인간의 피드백을 포함시켜, 도움이 되고 해가 없는 특성에 대해 모델을 학습시킬 수 있게 합니다.
* RLAIF : RLAIF는 Reinforcement Learning from AI Feedback의 약자로서 기존의 RLHF(Reinforcement Learning from Human Feedback)와 큰 차이가 나지 않는 성공율을 보여주는 인공지능 모델입니다.

=============================================================================

(생성 AI)
* 생성 AI (Generative AI) : 이미지, 텍스트, 음악, 비디오 등 새로운 콘텐츠를 만들어 내는 AI 모델과 알고리즘을 연구하는 분야를 의미함.
<응용 분야>
• 텍스트 기반 이미지 생성
• 이미지 기반 이미지 생성
• 이미지 채우기
• 비디오 생성
• 코드 생성
• 언어 번역
• 텍스트 합성
• 대화형 에이전트
• 예술 작품 생성
• 데이터 증강
• 의학 이미지 합성
<고려 사항>
• 학습 데이터의 품질 : 최신 인공지능 기술과 마찬가지로 학습 데이터의 품질이 매우 중요
• 사용자 입력의 중요성 : 원하는 수준의 결과 생성을 위해 사용자의 입력이 매우 중요
• 저작권 문제 및 윤리적 문제
• 생성 결과의 오용 문제
• 딥 페이크
• 거짓 정보/뉴스의 유통

* Text Generation : AI 모델을 이용하여 입력 프롬프트를 기반으로 인간이 작성한 것 같은 텍스트를 생성하는 것을 의미함.
< 동작 원리 >
• ChatGPT와 같은 GPT(Generative Pre-trained Transformer)에서는 Transformer architecture를 사용
• 방대한 텍스트 데이터를 기반으로 문법, 문맥, 의미론 등을 미리 학습
• 프롬프트를 제시하면, 학습한 패턴을 기반으로 다음 단어나 구문을 예측
< 응용 분야 >
• 텍스트 생성 기술은 콘텐츠 창작, 챗봇, 코드 생성 등에 적용할 수 있음
• 비즈니스에서는 이를 활용하여 블로그 포스팅을 하거나, 고객 지원 응대를 자동화하고, 코드 작성 등에 적용
• 마케팅 카피 문구를 작성하거나 고객 맞춤형 메시지를 작성할 수도 있음

* Image Generation : 다양한 딥러닝 모델을 활용하여 실제와 같은 이미지를 생성하는 것을 의미함.
< 동작 원리 >
• 대표적 생성 기술인 GAN(Generative Adversarial Networks -적대적 생성 신경망)은 이미지를 만드는 생성자(generator)와 진위여부를 판단하는 구별자(discriminator)로 구성됨 : 이 두 시스템이 피드백 루프에서 서로 경쟁을
하면서 생성자는 구별자가 진위여부를 판별할 수 없을 때까지 학습하며 더 좋은 이미지를 생성함
• GAN 외에도 VAE, Diffusion 등의 기술이 있으며, 최근에 발표된 모델들은 주로 Diffusion 모델을 사용
< 응용 분야 >
• 예술, 디자인, 제품 시각화 등에서 사용 가능
• 이미지 생성 및 복원, 동작을 흉내내는 인공지능, 신약 개발 등에 활용
• 비즈니스에서 광고를 위한 제품 모형을 만들거나, 브랜딩에 사용할 독창적인 미술작품을 만드는데도 사용 가능

* Audio Generation : 음악, 소리 및 인간과 같은 목소리를 생성하는 것을 의미함.
< 동작 원리 >
• 2014년 GAN이 소개된 이후 이미지 관련한 다수의 연구가 진행되다가 2018년 음성/소리 분야에도 GAN 기술이 적용됨(WaveGAN)
• Tacotron 2와 같은 TTS(Text-To-Speech, 텍스트를 음성으로 변환)는 텍스트를 입력 받아 음성 생성
• 대량의 데이터셋을 학습하여 소리 뉘앙스를 습득
<응용 분야>
• AI로 생성된 음악을 광고, 비디오, 배경 음악 등에서 사용할 수 있음
• 마케팅 캠페인에서 기억하기 쉬운 멜로디나 맞춤형 효과음 등 생성 가능
• TTS 기술을 써서 고객 서비스나 광고 나레이터 등을 자동화할 수 있음
• 브랜드 평가를 개선하거나 스토리텔링 등에
적용 가능
* Video Generation : 생성 기술을 통해 기존의 비디오를 결합하거나 빠진 부분을 보충하여 완성하는 식으로 비디오를 생성함.
<동작 원리>
• Video diffusion model 등을 이용하여 비디오 생성
• 텍스트 설명을 통해서 장면을 생성하거나, 특정 비디오에서 누락 또는 손상된 프레임을 예측하여 보충
• 비디오 생성은 시간 요소가 포함되기 때문에 이미지 생성보다 더 복잡함 : 시간적 일관성, 깊은 언어 이해, 영상 프레임 충실도
<응용 분야>
• 개인화된 메시지, 콘텐츠 마케팅에 사용 가능
• 브랜드에서 독창적인 비디오 광고를 통해서 특정 고객 계층을 공략할 수 있음
• 이를 통해서 효과적인 비디오 콘텐츠 제작이 가능

(Image 생성 AI)
* Image Generation – 생성 모델 : 잠재 공간에서 샘플링하여 새로운 데이터를 생성하거나 변형하는 모델
* Image Generation - GAN(Generative Adversarial Network) : 
• Generator : 
- 노이즈를 기반으로 원본과 가까운 가짜 이미지 생성
- 학습을 거듭하며 원본 데이터의 분포를 따라감
• Discriminator :
- Generator가 생성한 이미지를 판별함
* Image Generation - VAE(Variational AutoEncoder) : 샘플링하여 분포를 따르는 새로운 이미지 생성
[참고] AE(AutoEncoder)
[참고] 분포 학습 : 생성 모델 - 잠재 공간에서 샘플링하여 새로운 데이터를 생성하거나 변형하는 모델
이미지 데이터 확률 분포
• 이미지 데이터는 특징 공간의 한 점으로 표현 가능(CNN의 특징 추출)
• 각 특성의 빈도에 따라 확률 분포로 표현 가능함
• (예시) 얼굴 크기와 미간의 폭
* 확산 모델 (Diffusion Probabilistic Model) : 확산 모델은 학습 데이터에 지속적으로 잡음(noise)을 추가하여 손상시킨 후, 잡음을 제거해 가며 원상복구하는 방식의 생성 모델임.
* 순방향 확산(Forward Diffusion) : 순방향 확산 프로세스에서는 학습용 이미지에 점차적으로 잡음을 추가하여, 점점 아무런 특징이 없는 잡음 이미지로 변환해 감.
* 역방향 확산(Reverse Diffusion) : 역방향 확산은 잡음(잠재 공간)에서 출발해서 강아지 혹은 고양이 등의 이미지로 복구하는 것을 의미
* Image Generative AI의 현재
• 이미지 생성 분야에서 상당한 발전이 있어온 것은 사실이지만, 아직까지는 분명히 한계  존재
• 오른쪽 그림은  분야를 선도하고있는 OpenAI에서 DALL-E 3를 소개하는 페이지에 게시
•  자세히 들여다보면 세부적인 묘사는 아직까지 어색한 것들을 찾을 수 있음
* 오류사례: 손 : Prompt: Software developers painting a mural(손가락 표현에 어려움이 있음. 사람의 얼굴도 이상하게 나오는 경우 발생)

======================================================================================

Stable Diffusion 실습 프로젝트.


















