{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7879\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7879/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\chch4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chch4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\route_utils.py\", line 276, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chch4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 1897, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chch4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 1483, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chch4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chch4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chch4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chch4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\utils.py\", line 816, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\chch4\\AppData\\Local\\Temp\\ipykernel_22628\\3088101463.py\", line 33, in predict_image\n",
      "    results = predictor.classify_image_with_no_store(project_id, model_name, processed_image)  # 이미지 분류용 메서드\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\chch4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\azure\\cognitiveservices\\vision\\customvision\\prediction\\operations\\_custom_vision_prediction_client_operations.py\", line 147, in classify_image_with_no_store\n",
      "    raise models.CustomVisionErrorException(self._deserialize, response)\n",
      "azure.cognitiveservices.vision.customvision.prediction.models._models_py3.CustomVisionErrorException: Invalid project type for operation.\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import io\n",
    "import gradio as gr\n",
    "\n",
    "# Authenticate client\n",
    "prediction_key = \"00985879e591465d874bf6f503b501b6\"\n",
    "prediction_endpoint = \"https://team1customvision-prediction.cognitiveservices.azure.com/\"\n",
    "project_id = \"52a79c5c-b304-4134-83a9-2cdffb34734e\"\n",
    "model_name = \"Iteration1\"\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(endpoint=prediction_endpoint, credentials=credentials)\n",
    "\n",
    "data = {\n",
    "    \"Inputs\": {\n",
    "        \"input1\": [\n",
    "            {\n",
    "                \"paper\": \"이건 종이야!📄\\n종이는 종이끼리 모여진 데 버려주면 돼!\",\n",
    "                \"glass\": \"이건 유리야!🔍\\n유리병은 깨질 수 있으니 던지지 말고 조심히 버려줘!\",\n",
    "                \"metal\": \"이건 금속이야!🔧\\n날카로운 모서리에 손이 베이지 않게 조심해!\",\n",
    "                \"plastic\": \"이건 플라스틱이야!🌱\\n페트병은 라벨을 떼고 찌그러트려 버려줘!\",\n",
    "                \"trash\": \"이건 일반쓰레기야!🗑️\\n일반쓰레기는 종량제 봉투에 모아줄래?\\n종량제 봉투가 뭐냐구? 함께 알아볼까?\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"GlobalParameters\": {}\n",
    "}\n",
    "\n",
    "def predict_image(input_img):\n",
    "    h, w = input_img.size\n",
    "    img_byte_arr = io.BytesIO() \n",
    "    input_img.save(img_byte_arr, format='PNG') \n",
    "    img_bytes = img_byte_arr.getvalue() \n",
    "    results = predictor.detect_image(project_id, model_name, img_bytes) \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.axis('off') \n",
    "\n",
    "    draw = ImageDraw.Draw(input_img) \n",
    "    lineWidth = int(w / 100) \n",
    "    color = 'magenta'\n",
    "    \n",
    "    detected_objects = []\n",
    "    \n",
    "    print(\"Predictions:\")\n",
    "    for prediction in results.predictions:\n",
    "        print(f\"{prediction.tag_name}: {prediction.probability * 100:.2f}%\")\n",
    "        if (prediction.probability * 100) > 50:  # 확률 임계값을 50%로 낮춤\n",
    "            detected_objects.append(prediction.tag_name)\n",
    "            left = prediction.bounding_box.left * w \n",
    "            top = prediction.bounding_box.top * h \n",
    "            width = prediction.bounding_box.width * w \n",
    "            height = prediction.bounding_box.height * h \n",
    "\n",
    "            points = ((left, top), (left + width, top), (left + width, top + height), (left, top + height), (left, top)) \n",
    "            draw.line(points, fill=color, width=lineWidth) \n",
    "            ax.annotate(prediction.tag_name + ' {0:.2f}%'.format(prediction.probability * 100), (left, top), color=color)\n",
    "    \n",
    "    ax.imshow(input_img)\n",
    "    \n",
    "    # 예측 결과 텍스트 생성\n",
    "    predictions_text = \"\\n\".join(\n",
    "        f\"{prediction.tag_name}: {prediction.probability * 100:.2f}%\"\n",
    "        for prediction in results.predictions\n",
    "        if (prediction.probability * 100) > 50\n",
    "    )\n",
    "    \n",
    "    return fig, predictions_text\n",
    "\n",
    "result_output = gr.Textbox(label=\"Result\")\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=predict_image, \n",
    "    inputs=gr.Image(type='pil'), \n",
    "    outputs=[gr.Plot(), result_output]\n",
    ")\n",
    "demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
